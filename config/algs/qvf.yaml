# --- RL hyperparameters ---
gamma: 0.99
alpha: 0.7
batch_size: 8 # Number of episodes to train on
buffer_size: 5000 # Size of the replay buffer
lr: 0.0005 # Learning rate for agents
optimizer: "RMS"
grad_norm_clip: 0.5 # Reduce magnitude of gradients above this L2 norm
rnn_hidden_dim: 128
qmix_hidden_dim: 128
qtran_hidden_dim: 128
v_hidden_dim: 128
epsilon: 1
anneal_epsilon: 0.00064
min_epsilon: 0.05
epsilon_steps: 100000
save_cycle: 5000
target_update_interval: 300
train_steps: 8
n_episodes: 1
two_hyper_layers: False
hyper_hidden_dim: 128
double_Q: False
lambda_soft_update: 0.005
hard_update: False
last_action: True
reuse_network: True
log_interval: 200
epsilon_anneal_scale: episode
target_update_cycle: 300
td_type: td_lambda
q_total_type: individual
qmix_type: mix2
td_lambda: 0.95